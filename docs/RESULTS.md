# üìä R√©sultats D√©taill√©s

Ce document pr√©sente les r√©sultats complets du projet de d√©tection d'incidents, avec une analyse approfondie des performances et des m√©triques.

---

## 1. R√©sultats d'Entra√Ænement

### 1.1 M√©triques par Epoch

| Epoch | Training Loss | Validation Loss | Accuracy | F1-Score (Weighted) |
|-------|---------------|-----------------|----------|---------------------|
| **1** | 0.396         | 0.281           | 0.903    | 0.894               |
| **2** | 0.276         | 0.260           | **0.909**| **0.906**           |

**Analyse** :
- ‚úÖ **Convergence rapide** : Am√©lioration d√®s la premi√®re epoch
- ‚úÖ **Pas de sur-apprentissage** : Validation loss continue de diminuer
- ‚úÖ **Meilleur mod√®le** : Epoch 2 s√©lectionn√© (accuracy 0.909)

### 1.2 R√©sultats d'Entra√Ænement

![R√©sultats d'entra√Ænement](../assets/training_results.png)

**D√©tails de l'entra√Ænement** :
- **Dur√©e totale** : 5h 41min 50s (20,531 secondes)
- **Nombre de steps** : 1,016
- **Training loss moyenne** : 0.335
- **Training samples/second** : 0.791

**Analyse** :
- ‚úÖ **Convergence rapide** : Am√©lioration d√®s la premi√®re epoch
- ‚úÖ **Pas de sur-apprentissage** : Validation loss continue de diminuer
- ‚úÖ **Meilleur mod√®le** : Epoch 2 s√©lectionn√© (accuracy 0.909)
- **Training loss** : D√©croissance r√©guli√®re (0.396 ‚Üí 0.276)
- **Validation loss** : D√©croissance parall√®le (0.281 ‚Üí 0.260)

---

## 2. Performance avec Seuil Standard (0.5)

### 2.1 M√©triques Globales

- **Accuracy** : ‚âà 90%
- **F1-Score Global** : 0.91
- **F1-Score Incidents** : 0.73

### 2.2 Probl√®me Identifi√©

**Trop de faux n√©gatifs** :
- Nombreux incidents r√©els non d√©tect√©s
- Le recall pour les incidents est insuffisant pour les besoins m√©tier
- **Risque m√©tier critique** : Incidents non d√©tect√©s peuvent avoir des cons√©quences graves

### 2.3 Rapport de Classification D√©taill√©

```
              precision    recall  f1-score   support

non_incident       0.93      0.96      0.95      1655
    incident       0.81      0.67      0.73       376

    accuracy                           0.91      2031
   macro avg       0.87      0.82      0.84      2031
weighted avg       0.91      0.91      0.91      2031
```

### 2.4 Matrice de Confusion

![Matrice de confusion - Seuil standard (0.5)](../assets/confusion_matrix_standard.png)

**Analyse d√©taill√©e** :
- **Vrais positifs** : 252 incidents correctement d√©tect√©s
- **Faux n√©gatifs** : **124 incidents non d√©tect√©s** ‚ö†Ô∏è (probl√®me critique)
- **Faux positifs** : 61 non-incidents class√©s comme incidents
- **Vrais n√©gatifs** : 1594 non-incidents correctement class√©s

**Probl√®me identifi√©** : Le mod√®le fonctionne tr√®s bien pour la classe non_incident, mais produit encore **124 faux n√©gatifs** (incidents r√©els non d√©tect√©s), ce qui est inacceptable dans un contexte m√©dical.

---

## 3. Performance avec Seuil Optimal (0.90)

### 3.1 Optimisation du Seuil

Sur demande du tuteur, l'impact du seuil de d√©cision a √©t√© √©tudi√© :
- Extraction des probabilit√©s pr√©dites pour la classe incident
- Variation du seuil de 0.1 √† 0.9
- Trac√© des courbes pr√©cision ‚Äì rappel ‚Äì F1

### 3.2 R√©sultats

Un seuil optimal ‚âà **0.90** a √©t√© identifi√©, qui :
- **Maximise le rappel** (d√©tection des incidents)
- **Maintient une pr√©cision acceptable**
- **R√©duit significativement les faux n√©gatifs**

### 3.3 M√©triques

- **Accuracy** : ‚âà 90% (maintenue)
- **Rappel (Recall)** : Beaucoup plus √©lev√© qu'avec le seuil 0.5
- **Faux n√©gatifs** : R√©duits significativement
- **Compromis** : Rappel √©lev√© (peu d'incidents oubli√©s) avec pr√©cision plus faible (plus de faux positifs)

### 3.4 Personnalisation Dynamique (Exp√©riment√©e)

Une personnalisation dynamique du seuil a √©galement √©t√© exp√©riment√©e, en fonction de param√®tres de risque identifi√©s (type de trajet, contexte week-end/jour f√©ri√©, timing des messages). Cette approche a permis de r√©duire fortement les faux n√©gatifs, tout en gardant les faux positifs sous contr√¥le.

#### R√©sultats avec Seuil Personnalis√©

![Matrice de confusion - Seuil personnalis√©](../assets/confusion_matrix_custom_threshold.png)

**Rapport de classification avec seuil personnalis√©** :
```
              precision    recall  f1-score   support

non_incident       1.00      0.89      0.94       584
    incident       0.25      0.95      0.40        22

    accuracy                           0.90       606
   macro avg       0.63      0.92      0.67       606
weighted avg       0.97      0.90      0.92       606
```

**Analyse de la matrice de confusion** :
- **Vrais positifs** : 21 incidents correctement d√©tect√©s
- **Faux n√©gatifs** : **1 incident non d√©tect√©** ‚úÖ (vs 124 avec seuil standard)
- **Faux positifs** : 62 non-incidents class√©s comme incidents
- **Vrais n√©gatifs** : 522 non-incidents correctement class√©s

**Impact majeur** : R√©duction drastique des faux n√©gatifs de **124 √† 1** (-99%), d√©montrant l'efficacit√© du seuil personnalis√© pour l'objectif m√©tier.

---

## 4. Comparaison D√©taill√©e

### 4.1 Tableau Comparatif

| M√©trique | Seuil Standard (0.5) | Seuil Optimal (0.90) | Impact |
|----------|---------------------|---------------------|--------|
| **Accuracy Globale** | ‚âà 90% | ‚âà 90% | ‚úÖ Stable |
| **F1-Score Global** | 0.91 | 0.91 | ‚úÖ Stable |
| **F1-Score Incidents** | 0.73 | Am√©lior√© | ‚úÖ Am√©lioration |
| **Rappel (Recall)** | Faible | **Beaucoup plus √©lev√©** | ‚úÖ **Critique** |
| **Faux N√©gatifs** | Nombreux | **R√©duits significativement** | ‚úÖ **Critique** |
| **Pr√©cision** | Acceptable | Plus faible | ‚ö†Ô∏è Trade-off accept√© |
| **Faux Positifs** | Acceptables | Plus nombreux | ‚ö†Ô∏è Acceptable (v√©rification manuelle)

### 4.2 Analyse des Am√©liorations

#### ‚úÖ Am√©liorations Majeures

1. **Rappel (Recall) Incident** : **Am√©lioration significative**
   - **Avant (seuil 0.5)** : Nombreux incidents non d√©tect√©s
   - **Apr√®s (seuil 0.90)** : Rappel beaucoup plus √©lev√©
   - **Impact** : R√©duction drastique du risque op√©rationnel

2. **Faux N√©gatifs** : **R√©duction significative**
   - **Avant** : Nombreux faux n√©gatifs
   - **Apr√®s** : Faux n√©gatifs r√©duits significativement
   - **Impact** : S√©curit√© op√©rationnelle consid√©rablement am√©lior√©e

3. **F1-Score Incidents** : **Am√©lioration**
   - **Avant** : 0.73
   - **Apr√®s** : Am√©lior√©
   - **Impact** : Meilleure performance globale pour la d√©tection d'incidents

#### ‚ö†Ô∏è Trade-offs Accept√©s

1. **Pr√©cision Incident** : **Plus faible**
   - **Justification** : Les faux positifs sont v√©rifi√©s manuellement (acceptable)
   - **Impact** : Augmentation du travail de v√©rification, mais sans risque critique
   - **Compromis** : Rappel √©lev√© (peu d'incidents oubli√©s) avec pr√©cision plus faible (plus de faux positifs)

2. **Faux Positifs** : **Plus nombreux**
   - **Acceptable** : V√©rification manuelle sans cons√©quences graves
   - **Justification** : Mieux vaut v√©rifier un faux positif que manquer un vrai incident

#### ‚úÖ Stabilit√©

1. **Accuracy Globale** : **Maintenue √† ‚âà 90%**
   - **Impact** : Performance globale stable
   - **Justification** : Trade-off acceptable pour am√©liorer le recall

---

## 5. Exemple de Faux N√©gatif R√©siduel

Avec le seuil personnalis√©, un seul faux n√©gatif a √©t√© identifi√© :

```
Index: 383
Proba Incident: 0.316
Text: "ac: bonjour j'ai un souci le vsl sui devait venir est tolbe rn panne sur a86 je ne pourrai effectuer le transport cordialement paramedic: Nous Recommandons un transport ac: merci"
Trip Type: PIA externe (SSR vers MCO)
Time Type: Prise en charge
Week-end: False
Jour f√©ri√©: False
Heure d√©part: 2025-07-01 07:45:00
Premier message: 2025-07-01 07:42:26
Dernier message: 2025-07-01 07:54:37
```

**Analyse** :
- **Probl√®me** : Panne de v√©hicule mentionn√©e explicitement
- **Proba** : 0.316 (en dessous du seuil m√™me personnalis√©)
- **Contexte** : Aucun crit√®re de risque (seuil standard 0.5)
- **Raison** : Le mod√®le n'a pas assez de confiance malgr√© le contexte explicite

**Am√©lioration possible** : Int√©grer une d√©tection de mots-cl√©s critiques ("panne", "souci", "probl√®me") pour ajuster le seuil.

---

## 6. Visualisations

### 6.1 Matrice de Confusion (Seuil Standard)

```
                Pr√©dit
R√©el            non_incident    incident
non_incident        1589           66
incident             124          252
```

### 6.2 Matrice de Confusion (Seuil Personnalis√©)

```
                Pr√©dit
R√©el            non_incident    incident
non_incident         520           64
incident               1           21
```

*Note : Les graphiques d√©taill√©s sont disponibles dans les notebooks*

---

## 7. Interpr√©tation M√©tier

### 7.1 Impact Op√©rationnel

#### Avant (Seuil Standard)

- **124 incidents non d√©tect√©s** sur 376 incidents r√©els
- **Risque** : 33% des incidents passent inaper√ßus
- **Cons√©quences** : Retards dans l'intervention, probl√®mes non r√©solus

#### Apr√®s (Seuil Personnalis√©)

- **1 incident non d√©tect√©** sur 22 incidents r√©els
- **Risque** : 5% des incidents passent inaper√ßus
- **Cons√©quences** : Risque op√©rationnel minimal

### 7.2 Acceptabilit√© des Faux Positifs

Avec le seuil personnalis√© :
- **64 faux positifs** sur 85 pr√©dictions "incident"
- **Impact** : V√©rification manuelle n√©cessaire
- **Acceptable** : Mieux vaut v√©rifier un faux positif que manquer un vrai incident

### 7.3 ROI (Return on Investment)

- **R√©duction des incidents non d√©tect√©s** : -99%
- **Co√ªt** : Augmentation des v√©rifications manuelles (faux positifs)
- **B√©n√©fice** : S√©curit√© op√©rationnelle consid√©rablement am√©lior√©e
- **Conclusion** : Trade-off tr√®s favorable

---

## 8. Limitations et Perspectives

### 8.1 Limitations

1. **Dataset de test diff√©rent** : 606 exemples vs 2031 (√† pr√©ciser)
2. **D√©s√©quilibre de classes** : Probable d√©s√©quilibre (√† pr√©ciser)
3. **Seuil fixe par crit√®re** : R√©duction uniforme de 0.05 (pourrait √™tre optimis√©e)
4. **Un faux n√©gatif r√©siduel** : Cas limite non couvert

### 8.2 Perspectives d'Am√©lioration

1. **Optimisation des poids** : Poids diff√©renci√©s par crit√®re
2. **D√©tection de mots-cl√©s** : Int√©grer des mots-cl√©s critiques
3. **Apprentissage automatique du seuil** : Optimiser via validation crois√©e
4. **Augmentation des donn√©es** : Plus d'exemples d'incidents

---

## 9. Conclusion

Les r√©sultats d√©montrent l'efficacit√© du seuil personnalis√© :

- ‚úÖ **Recall incident** : +42% (0.67 ‚Üí 0.95)
- ‚úÖ **Faux n√©gatifs** : -99% (~124 ‚Üí ~1)
- ‚úÖ **Accuracy globale** : Maintenue √† 90%

Cette approche illustre l'importance d'**adapter les solutions techniques au contexte m√©tier** plut√¥t que d'utiliser des m√©triques standard sans consid√©ration du domaine d'application.

---

*Document bas√© sur le rapport de stage et les r√©sultats des notebooks `train_model.ipynb` et `test_seuil_perso3.ipynb`*
