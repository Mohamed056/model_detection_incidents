# üìñ M√©thodologie D√©taill√©e

Ce document pr√©sente la m√©thodologie compl√®te du projet de d√©tection d'incidents dans les communications de transport m√©dical.

---

## 1. Contexte et Objectifs

### 1.1 Probl√©matique

Dans le domaine du transport m√©dical, les communications entre transporteurs et op√©rateurs peuvent contenir des informations critiques sur des incidents (retards, pannes, probl√®mes de transport, etc.). La d√©tection manuelle de ces incidents est :
- **Co√ªteuse** : N√©cessite une surveillance humaine constante
- **Lente** : D√©lai entre l'incident et sa d√©tection
- **Erreur humaine** : Risque de manquer des incidents importants

### 1.2 Objectifs

1. **Automatiser la d√©tection** : Identifier automatiquement les incidents dans les communications
2. **R√©duire les faux n√©gatifs** : Minimiser le risque de ne pas d√©tecter un incident r√©el
3. **Adapter au contexte m√©tier** : Prendre en compte les facteurs de risque sp√©cifiques au transport m√©dical

---

## 2. Pipeline NLP Complet

### 2.1 Collecte et Pr√©paration des Donn√©es

#### Extraction depuis MongoDB

Les conversations ont √©t√© extraites depuis la base MongoDB en utilisant des scripts Python (via la librairie `pymongo`) :
- Identification des conversations contenant des incidents gr√¢ce aux champs internes (`incident`, `incident_report`, `not_incident`)
- Nettoyage des donn√©es : suppression des messages automatiques, des doublons et des textes trop courts
- Export dans un format JSONL structur√©, pr√™t pour l'entra√Ænement

#### Format des Donn√©es

Les donn√©es sont au format **JSONL** (JSON Lines), o√π chaque ligne repr√©sente un exemple. Les messages d'une m√™me conversation sont **concat√©n√©s en un bloc unique**.

#### Split Train/Test

- **Train** : 8,123 exemples
- **Test** : 2,031 exemples
- **Distribution** : D√©s√©quilibre conserv√© (beaucoup plus de non-incidents que d'incidents) pour refl√©ter la r√©alit√© et simuler les conditions de production

#### Encodage des Labels

```python
label2id = {
    "non_incident": 0,
    "incident": 1
}
```

### 2.2 Pr√©processing

#### Tokenisation avec CamemBERT

```python
from transformers import CamembertTokenizer

tokenizer = CamembertTokenizer.from_pretrained("camembert-base")

def tokenize_function(batch):
    return tokenizer(
        batch["text"],
        padding="max_length",
        truncation=True,
        max_length=128
    )
```

**Choix techniques** :
- **Padding** : `max_length` pour uniformiser les s√©quences
- **Truncation** : Limite √† 128 tokens
- **Distribution r√©elle** : M√©diane ‚âà 38 tokens, 75e centile ‚âà 69 tokens, max ‚âà 1097 tokens
- **Justification** : 128 tokens couvre la grande majorit√© des conversations tout en limitant le temps de calcul

### 2.3 Mod√®le : CamemBERT

#### Architecture

- **Mod√®le de base** : `camembert-base` (Hugging Face)
- **Architecture** : Transformer BERT adapt√© au fran√ßais
- **Param√®tres** : ~110M de param√®tres
- **Vocabulaire** : 32,000 tokens (SentencePiece)

#### Adaptation pour la Classification

```python
from transformers import CamembertForSequenceClassification

model = CamembertForSequenceClassification.from_pretrained(
    "camembert-base",
    num_labels=2  # Classification binaire
)
```

Le mod√®le ajoute une couche de classification lin√©aire :
- **Input** : Repr√©sentation du [CLS] token (768 dimensions)
- **Output** : 2 logits (non_incident, incident)

### 2.4 Entra√Ænement

#### Hyperparam√®tres

```python
TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,  # Limitation m√©moire GPU
    num_train_epochs=2,
    weight_decay=0.01,               # Pour √©viter l'overfitting
    # Scheduler cosine avec warmup
)
```

#### Justifications des Hyperparam√®tres

- **Learning rate 2e-5** : Standard pour le fine-tuning de BERT
- **Batch size 16** : Limitation m√©moire GPU (Google Colab)
- **2 epochs** : Assure une convergence rapide
- **Weight decay 0.01** : Pour √©viter l'overfitting
- **Scheduler cosine avec warmup** : Optimisation de l'apprentissage

#### Infrastructure d'Entra√Ænement

- **Plateforme** : Google Colab (acc√®s gratuit aux GPU)
- **Dur√©e** : Entra√Ænements sur plusieurs heures
- **Flexibilit√©** : Permet de tester diff√©rents param√®tres

#### M√©triques d'√âvaluation

```python
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    acc = accuracy_score(labels, predictions)
    f1 = f1_score(labels, predictions, average="weighted")
    return {"accuracy": acc, "f1": f1}
```

### 2.5 R√©sultats d'Entra√Ænement

![R√©sultats d'entra√Ænement](../assets/training_results.png)

#### M√©triques d'Entra√Ænement

| Epoch | Training Loss | Validation Loss | Accuracy | F1-Score (Weighted) |
|-------|---------------|-----------------|----------|---------------------|
| 1     | 0.396         | 0.281           | 0.903    | 0.894               |
| 2     | 0.276         | 0.260           | 0.909    | 0.906               |

**D√©tails techniques** :
- **Dur√©e totale** : 5h 41min 50s
- **Nombre de steps** : 1,016
- **Training samples/second** : 0.791

#### Performance sur le Test Set (Seuil Standard 0.5)

- **Accuracy** : ‚âà 90%
- **F1-Score Global** : 0.91
- **F1-Score Incidents** : 0.73

**Analyse** :
- ‚úÖ **Accuracy globale** : ‚âà 90% (excellente)
- ‚úÖ **F1-Score global** : 0.91 (tr√®s bon)
- ‚ö†Ô∏è **F1-Score incidents** : 0.73 (acceptable mais perfectible)
- ‚ö†Ô∏è **Faux n√©gatifs** : La matrice de confusion a montr√© que le mod√®le produisait encore des faux n√©gatifs (incidents r√©els non d√©tect√©s)

---

## 3. Optimisation du Seuil de Classification

Voir [THRESHOLD_OPTIMIZATION.md](THRESHOLD_OPTIMIZATION.md) pour les d√©tails complets.

### 3.1 Probl√©matique du Seuil Standard

Avec un seuil fixe √† 0.5 :
- **Trop de faux n√©gatifs** (incidents r√©els non d√©tect√©s)
- **Risque m√©tier** : Un incident non d√©tect√© peut avoir des cons√©quences graves

### 3.2 Solution 1 : Seuil Optimal Fixe (0.90)

Sur demande du tuteur, l'impact du seuil de d√©cision a √©t√© √©tudi√© :
- Extraction des probabilit√©s pr√©dites pour la classe incident
- Variation du seuil de 0.1 √† 0.9
- Trac√© des courbes pr√©cision ‚Äì rappel ‚Äì F1

**R√©sultat** : Un seuil optimal ‚âà **0.90** a √©t√© identifi√©, qui :
- Maximise le rappel (d√©tection des incidents)
- Maintient une pr√©cision acceptable
- R√©duit significativement les faux n√©gatifs

### 3.3 Solution 2 : Personnalisation Dynamique (Exp√©riment√©e)

Une personnalisation dynamique du seuil a √©galement √©t√© exp√©riment√©e, en fonction de param√®tres de risque identifi√©s :
- Type de trajet
- Contexte week-end/jour f√©ri√©
- Timing des messages

Cette approche a permis de r√©duire fortement les faux n√©gatifs, tout en gardant les faux positifs sous contr√¥le.

---

## 4. √âvaluation et Validation

### 4.1 M√©triques Utilis√©es

- **Accuracy** : Performance globale
- **Precision** : Fiabilit√© des pr√©dictions positives
- **Recall** : Capacit√© √† d√©tecter tous les incidents
- **F1-Score** : Moyenne harmonique precision/recall
- **Matrice de confusion** : Visualisation des erreurs

### 4.2 Focus sur le Recall

Dans ce contexte m√©tier, **le recall est plus important que la precision** :
- **Faux n√©gatif** : Incident non d√©tect√© ‚Üí **Risque critique**
- **Faux positif** : Alerte sur un non-incident ‚Üí V√©rification manuelle (acceptable)

### 4.3 Validation M√©tier

Le seuil personnalis√© a √©t√© valid√© avec les experts m√©tier pour :
- ‚úÖ R√©duire drastiquement les faux n√©gatifs
- ‚úÖ Maintenir une accuracy globale acceptable
- ‚úÖ Adapter le syst√®me aux contraintes op√©rationnelles

---

## 5. Limitations et Am√©liorations Futures

### 5.1 Limitations Actuelles

- **Dataset** : Taille limit√©e (8K train, 2K test)
- **D√©s√©quilibre** : Probable d√©s√©quilibre de classes (√† pr√©ciser)
- **Features m√©tier** : Int√©gration manuelle des facteurs de risque
- **Seuil fixe** : R√©duction de 0.05 par crit√®re (pourrait √™tre optimis√©e)

### 5.2 Am√©liorations Possibles

1. **Augmentation des donn√©es** :
   - Data augmentation (paraphrasing, back-translation)
   - Collecte de plus d'exemples d'incidents

2. **Optimisation du seuil** :
   - Apprentissage automatique des poids par crit√®re
   - Seuil adaptatif selon la distribution des probabilit√©s

3. **Features additionnelles** :
   - Sentiment analysis
   - Entit√©s nomm√©es (lieux, heures, noms)
   - Historique du transporteur

4. **Mod√®les alternatifs** :
   - CamemBERT-large (plus de param√®tres)
   - Mod√®les sp√©cialis√©s domaine m√©dical
   - Ensemble de mod√®les

---

## 6. Conclusion

Cette m√©thodologie pr√©sente un pipeline NLP complet pour la d√©tection d'incidents, avec une innovation majeure : **l'adaptation du seuil de classification au contexte m√©tier**. Cette approche permet de r√©duire drastiquement les faux n√©gatifs tout en maintenant une performance globale √©lev√©e.

---

*Document bas√© sur le rapport de stage et les notebooks d'exp√©rimentation*
