# üèóÔ∏è Architecture du Projet

Ce document pr√©sente l'architecture technique et la structure du projet de d√©tection d'incidents.

---

## 1. Vue d'Ensemble

```
Model paramedic/
‚îÇ
‚îú‚îÄ‚îÄ README.md                    # Documentation principale (orient√©e recruteur)
‚îú‚îÄ‚îÄ ARCHITECTURE.md              # Ce fichier
‚îú‚îÄ‚îÄ .gitignore                   # Fichiers √† ignorer
‚îÇ
‚îú‚îÄ‚îÄ docs/                        # Documentation d√©taill√©e
‚îÇ   ‚îú‚îÄ‚îÄ METHODOLOGY.md           # M√©thodologie compl√®te
‚îÇ   ‚îú‚îÄ‚îÄ THRESHOLD_OPTIMIZATION.md # Optimisation du seuil
‚îÇ   ‚îî‚îÄ‚îÄ RESULTS.md               # R√©sultats d√©taill√©s
‚îÇ
‚îî‚îÄ‚îÄ notebooks/                   # Notebooks d'exp√©rimentation
    ‚îú‚îÄ‚îÄ train_model.ipynb        # Entra√Ænement du mod√®le CamemBERT
    ‚îî‚îÄ‚îÄ test_seuil_perso3.ipynb  # Tests du seuil personnalis√©
```

---

## 2. Pipeline de Traitement

### 2.1 Flux de Donn√©es

```
Donn√©es brutes (JSONL)
    ‚Üì
Pr√©processing
    ‚îú‚îÄ‚îÄ Encodage des labels (non_incident: 0, incident: 1)
    ‚îî‚îÄ‚îÄ Tokenisation (CamemBERT, max_length=128)
    ‚Üì
Dataset Hugging Face
    ‚îú‚îÄ‚îÄ Train (8,123 exemples)
    ‚îî‚îÄ‚îÄ Test (2,031 exemples)
    ‚Üì
Entra√Ænement
    ‚îú‚îÄ‚îÄ Mod√®le: CamemBERT-base
    ‚îú‚îÄ‚îÄ Fine-tuning: 2 epochs
    ‚îî‚îÄ‚îÄ Hyperparam√®tres optimis√©s
    ‚Üì
Mod√®le entra√Æn√©
    ‚Üì
√âvaluation
    ‚îú‚îÄ‚îÄ Seuil standard (0.5)
    ‚îî‚îÄ‚îÄ Seuil personnalis√© (dynamique)
    ‚Üì
R√©sultats et m√©triques
```

### 2.2 Composants Principaux

#### 2.2.1 Pr√©processing

- **Format d'entr√©e** : JSONL (une ligne par exemple)
- **Champs utilis√©s** :
  - `text` : Message de communication
  - `label` : Label (non_incident / incident)
  - `trip_type` : Type de transport
  - `time_type` : Type de temps
  - `is_weekend` : Bool√©en
  - `is_bank_holidays` : Bool√©en
  - `dt_starting` : Heure de d√©part pr√©vue
  - `first_message_dt` : Heure du premier message
  - `latest_message_dt` : Heure du dernier message

- **Tokenisation** :
  - Tokenizer : `CamembertTokenizer`
  - Max length : 128 tokens
  - Padding : `max_length`
  - Truncation : Activ√©e

#### 2.2.2 Mod√®le

- **Architecture** : `CamembertForSequenceClassification`
- **Base** : `camembert-base` (Hugging Face)
- **Param√®tres** : ~110M
- **Sortie** : 2 logits (classification binaire)

#### 2.2.3 Entra√Ænement

- **Framework** : Hugging Face Transformers (Trainer)
- **Backend** : PyTorch
- **Hyperparam√®tres** : Voir [METHODOLOGY.md](docs/METHODOLOGY.md)

#### 2.2.4 Classification

- **Seuil standard** : 0.5 (par d√©faut)
- **Seuil personnalis√©** : Dynamique selon le contexte
  - Base : 0.5
  - R√©duction : -0.05 par crit√®re de risque
  - Minimum : 0.3

---

## 3. Architecture du Mod√®le

### 3.1 CamemBERT

```
Input (Text)
    ‚Üì
Tokenization (SentencePiece)
    ‚Üì
Embeddings (Token + Position + Segment)
    ‚Üì
Transformer Encoder (12 layers)
    ‚îú‚îÄ‚îÄ Multi-Head Attention (12 heads)
    ‚îú‚îÄ‚îÄ Feed Forward Network
    ‚îî‚îÄ‚îÄ Layer Normalization
    ‚Üì
[CLS] Token Representation (768 dim)
    ‚Üì
Classification Head
    ‚îú‚îÄ‚îÄ Dense Layer (768 ‚Üí 768)
    ‚îú‚îÄ‚îÄ Activation (ReLU)
    ‚îî‚îÄ‚îÄ Output Layer (768 ‚Üí 2)
    ‚Üì
Logits (2 classes)
    ‚Üì
Softmax
    ‚Üì
Probabilit√©s [P(non_incident), P(incident)]
```

### 3.2 Classification avec Seuil Personnalis√©

```
Probabilit√©s du mod√®le
    ‚Üì
P(incident) = probas[:, 1]
    ‚Üì
Calcul du seuil personnalis√©
    ‚îú‚îÄ‚îÄ Seuil de base: 0.5
    ‚îú‚îÄ‚îÄ R√©duction par crit√®re de risque: -0.05
    ‚îî‚îÄ‚îÄ Seuil minimum: 0.3
    ‚Üì
Comparaison: P(incident) > seuil_personnalise ?
    ‚Üì
Pr√©diction finale
```

---

## 4. Technologies et D√©pendances

### 4.1 Biblioth√®ques Principales

- **transformers** (Hugging Face) : Mod√®les pr√©-entra√Æn√©s et fine-tuning
- **datasets** (Hugging Face) : Gestion des datasets
- **torch** (PyTorch) : Backend de calcul
- **scikit-learn** : M√©triques et √©valuation
- **numpy** : Calculs num√©riques
- **matplotlib/seaborn** : Visualisations

### 4.2 Versions

*√Ä pr√©ciser selon l'environnement utilis√©*

- Python : 3.8+
- transformers : 4.x+
- torch : 1.x+
- scikit-learn : 1.x+

---

## 5. Structure des Donn√©es

### 5.1 Format d'Entr√©e (JSONL)

```json
{
  "text": "paramedic: Bonjour, un transporteur propose une PEC √† 14h30...",
  "label": "incident",
  "trip_type": "Retour √† domicile",
  "time_type": "Rendez-vous",
  "is_weekend": false,
  "is_bank_holidays": false,
  "dt_starting": "2025-07-01 07:45:00",
  "first_message_dt": "2025-07-01 07:42:26",
  "latest_message_dt": "2025-07-01 07:54:37",
  "ambulance_company": "Ambulances Clichy"
}
```

### 5.2 Format Apr√®s Tokenisation

```python
{
  "input_ids": [5, 1234, 5678, ...],  # Tokens encod√©s
  "attention_mask": [1, 1, 1, ...],    # Masque d'attention
  "label": 1                           # Label encod√© (0 ou 1)
}
```

### 5.3 Format de Sortie

```python
{
  "predictions": [[logit_0, logit_1], ...],  # Logits bruts
  "label_ids": [0, 1, 0, ...],               # Labels r√©els
  "probabilities": [[0.8, 0.2], ...]         # Probabilit√©s (softmax)
}
```

---

## 6. Flux d'Ex√©cution

### 6.1 Phase d'Entra√Ænement

1. **Chargement des donn√©es** : Lecture des fichiers JSONL
2. **Pr√©processing** : Encodage des labels et tokenisation
3. **Initialisation du mod√®le** : Chargement de `camembert-base`
4. **Configuration de l'entra√Ænement** : Hyperparam√®tres
5. **Entra√Ænement** : Fine-tuning sur 2 epochs
6. **Sauvegarde** : Mod√®le et tokenizer sauvegard√©s

### 6.2 Phase d'√âvaluation

1. **Chargement du mod√®le** : Mod√®le entra√Æn√©
2. **Pr√©processing du test** : Tokenisation des donn√©es de test
3. **Pr√©diction** : G√©n√©ration des probabilit√©s
4. **Classification avec seuil standard** : Seuil fixe √† 0.5
5. **Classification avec seuil personnalis√©** : Seuil dynamique
6. **√âvaluation** : Calcul des m√©triques (precision, recall, F1, accuracy)
7. **Visualisation** : Matrices de confusion

---

## 7. Points d'Extension

### 7.1 Am√©liorations Possibles

1. **Pipeline de production** :
   - API REST pour la pr√©diction en temps r√©el
   - Int√©gration dans un syst√®me de monitoring
   - Alertes automatiques

2. **Optimisation** :
   - Quantification du mod√®le (r√©duction de taille)
   - Optimisation pour l'inf√©rence (ONNX, TensorRT)
   - Mise en cache des pr√©dictions

3. **Monitoring** :
   - Tracking des performances en production
   - D√©tection de d√©rive (data drift)
   - A/B testing des seuils

4. **Am√©lioration du mod√®le** :
   - Fine-tuning continu (online learning)
   - Ensemble de mod√®les
   - Mod√®les sp√©cialis√©s par type d'incident

---

## 8. S√©curit√© et Confidentialit√©

### 8.1 Donn√©es Sensibles

- ‚ö†Ô∏è **Aucune donn√©e confidentielle** : Les exemples pr√©sent√©s sont fictifs
- ‚ö†Ô∏è **Anonymisation** : Aucun nom r√©el d'entreprise ou de client
- ‚ö†Ô∏è **Conformit√©** : Respect des r√©glementations (RGPD, etc.)

### 8.2 Bonnes Pratiques

- **Versioning** : Git pour le code
- **Documentation** : Documentation compl√®te du projet
- **Tests** : Validation sur donn√©es de test s√©par√©es
- **Reproductibilit√©** : Seeds fixes pour la reproductibilit√©

---

## 9. D√©ploiement

### 9.1 Environnement de D√©veloppement

- **Notebooks Jupyter** : Exp√©rimentation et prototypage
- **Google Colab** : Entra√Ænement sur GPU (si utilis√©)

### 9.2 Production (Perspectives)

- **API REST** : Flask/FastAPI pour servir le mod√®le
- **Containerisation** : Docker pour l'isolation
- **Orchestration** : Kubernetes pour la scalabilit√©
- **Monitoring** : Logs et m√©triques de performance

---

## 10. Conclusion

Cette architecture pr√©sente un pipeline NLP complet et modulaire pour la d√©tection d'incidents, avec une innovation majeure : **l'adaptation dynamique du seuil de classification au contexte m√©tier**. La structure est con√ßue pour √™tre extensible et maintenable, permettant des am√©liorations futures.

---

*Document bas√© sur l'analyse des notebooks et la m√©thodologie du projet*
