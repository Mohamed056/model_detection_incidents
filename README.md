# ğŸš‘ DÃ©tection d'Incidents dans les Communications de Transport MÃ©dical

> Projet de classification NLP utilisant CamemBERT pour identifier automatiquement les incidents dans les Ã©changes de communication entre transporteurs mÃ©dicaux et opÃ©rateurs.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Transformers](https://img.shields.io/badge/Transformers-HuggingFace-orange.svg)](https://huggingface.co/)
[![CamemBERT](https://img.shields.io/badge/Model-CamemBERT-green.svg)](https://huggingface.co/camembert-base)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Portfolio-yellow.svg)](https://github.com)

**ğŸ¯ RÃ©sultat clÃ©** : RÃ©duction des faux nÃ©gatifs de **124 Ã  1** (-99%) grÃ¢ce Ã  l'optimisation du seuil de classification.

## ğŸ“‹ RÃ©sumÃ© ExÃ©cutif

Ce projet prÃ©sente un systÃ¨me de classification binaire utilisant le modÃ¨le de langue franÃ§ais **CamemBERT** pour dÃ©tecter automatiquement les incidents dans les communications de transport mÃ©dical. L'innovation principale rÃ©side dans l'implÃ©mentation d'un **seuil de classification personnalisÃ© et dynamique** qui s'adapte aux contextes mÃ©tier, permettant de rÃ©duire significativement les faux nÃ©gatifs tout en maintenant une prÃ©cision Ã©levÃ©e.

### ğŸ¯ Objectifs MÃ©tier

- **RÃ©duction des faux nÃ©gatifs** : Minimiser le risque de ne pas dÃ©tecter un incident rÃ©el (critique dans le domaine mÃ©dical)
- **Optimisation du seuil de classification** : Adaptation dynamique selon le contexte (type de transport, horaires, jours fÃ©riÃ©s, etc.)
- **Automatisation** : DÃ©tection en temps rÃ©el des incidents pour amÃ©liorer la rÃ©activitÃ© opÃ©rationnelle

### ğŸ“Š RÃ©sultats ClÃ©s

| MÃ©trique | Seuil Standard (0.5) | Seuil Optimal (0.90) | AmÃ©lioration |
|----------|----------------------|---------------------|--------------|
| **Accuracy Globale** | â‰ˆ 90% | â‰ˆ 90% | Stable |
| **F1-Score Global** | 0.91 | 0.91 | Stable |
| **F1-Score Incidents** | 0.73 | AmÃ©liorÃ© | + |
| **Recall (Incident)** | Faible | **Beaucoup plus Ã©levÃ©** | **+++** |
| **Faux NÃ©gatifs** | Nombreux | **RÃ©duits significativement** | **RÃ©duction majeure** |

> **Note** : Le choix mÃ©tier privilÃ©gie le recall Ã©levÃ© pour les incidents, acceptant une augmentation des faux positifs afin de garantir qu'aucun incident rÃ©el ne soit manquÃ©.

---

## ğŸ—ï¸ Architecture du Projet

```
Model paramedic/
â”‚
â”œâ”€â”€ README.md                 # Ce fichier
â”œâ”€â”€ ARCHITECTURE.md           # Architecture technique
â”œâ”€â”€ docs/                     # Documentation dÃ©taillÃ©e
â”‚   â”œâ”€â”€ METHODOLOGY.md        # MÃ©thodologie complÃ¨te
â”‚   â”œâ”€â”€ THRESHOLD_OPTIMIZATION.md  # Optimisation du seuil
â”‚   â””â”€â”€ RESULTS.md            # RÃ©sultats dÃ©taillÃ©s
â”‚
â”œâ”€â”€ notebooks/                # Notebooks d'expÃ©rimentation
â”‚   â”œâ”€â”€ train_model.ipynb     # EntraÃ®nement du modÃ¨le CamemBERT
â”‚   â””â”€â”€ test_seuil_perso3.ipynb  # Tests du seuil personnalisÃ©
â”‚
â”œâ”€â”€ assets/                   # Images et visualisations
â”‚   â”œâ”€â”€ training_results.png
â”‚   â”œâ”€â”€ confusion_matrix_standard.png
â”‚   â””â”€â”€ confusion_matrix_custom_threshold.png
â”‚
â””â”€â”€ .gitignore
```

---

## ğŸ”¬ MÃ©thodologie

### 1. ModÃ¨le de Base : CamemBERT

- **ModÃ¨le** : `camembert-base` (Hugging Face)
- **Architecture** : Transformer BERT adaptÃ© au franÃ§ais
- **TÃ¢che** : Classification binaire (incident / non_incident)
- **Fine-tuning** : 2 epochs avec learning rate 2e-5

#### HyperparamÃ¨tres d'EntraÃ®nement

```python
TrainingArguments(
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=2,
    weight_decay=0.01,
    warmup_steps=200,
    lr_scheduler_type="cosine",
    metric_for_best_model="accuracy"
)
```

#### Dataset

- **Train** : 8,123 exemples
- **Test** : 2,031 exemples
- **Format** : JSONL avec champs `text` et `label`
- **Labels** : `non_incident` (0) / `incident` (1)

### 2. Innovation : Optimisation du Seuil de Classification

Le seuil standard (0.5) produisait trop de faux nÃ©gatifs. AprÃ¨s analyse des courbes prÃ©cision-rappel-F1, un **seuil optimal de 0.90** a Ã©tÃ© identifiÃ©, permettant de maximiser le rappel (dÃ©tection des incidents) tout en maintenant une prÃ©cision acceptable.

#### Approche 1 : Seuil Fixe Optimal

- **Seuil standard** : 0.5 â†’ Trop de faux nÃ©gatifs
- **Seuil optimal** : 0.90 â†’ Rappel beaucoup plus Ã©levÃ©, faux nÃ©gatifs rÃ©duits significativement

#### Approche 2 : Personnalisation Dynamique (ExpÃ©rimentÃ©e)

Une personnalisation dynamique du seuil a Ã©galement Ã©tÃ© expÃ©rimentÃ©e, en fonction de paramÃ¨tres de risque identifiÃ©s :
- Type de trajet
- Contexte week-end/jour fÃ©riÃ©
- Timing des messages

Cette approche a permis de rÃ©duire fortement les faux nÃ©gatifs, tout en gardant les faux positifs sous contrÃ´le.

---

## ğŸ“ˆ RÃ©sultats DÃ©taillÃ©s

### Performance avec Seuil Standard (0.5)

- **Accuracy** : â‰ˆ 90%
- **F1-Score Global** : 0.91
- **F1-Score Incidents** : 0.73
- **ProblÃ¨me** : **124 faux nÃ©gatifs** (incidents rÃ©els non dÃ©tectÃ©s) âš ï¸

![Matrice de confusion - Seuil standard](assets/confusion_matrix_standard.png)

### Performance avec Seuil PersonnalisÃ©

- **Accuracy** : â‰ˆ 90% (maintenue)
- **Rappel (Recall)** : 0.95 (vs 0.67 avec seuil standard)
- **Faux nÃ©gatifs** : **1 seul** (vs 124 avec seuil standard) âœ…
- **Compromis** : Rappel Ã©levÃ© (peu d'incidents oubliÃ©s) avec prÃ©cision plus faible (plus de faux positifs)

![Matrice de confusion - Seuil personnalisÃ©](assets/confusion_matrix_custom_threshold.png)

### Analyse

- âœ… **Rappel incident** : AmÃ©lioration significative
- âœ… **Faux nÃ©gatifs** : RÃ©duction majeure
- âš ï¸ **PrÃ©cision incident** : Plus faible (trade-off acceptÃ© pour maximiser la dÃ©tection)
- âœ… **Accuracy globale** : Maintenue Ã  â‰ˆ 90%

---

## ğŸ’¡ Choix Techniques et Justifications

### Pourquoi CamemBERT ?

- **SpÃ©cialisÃ© franÃ§ais** : EntraÃ®nÃ© sur un large corpus franÃ§ais
- **Performance** : Ã‰tat de l'art pour les tÃ¢ches NLP en franÃ§ais
- **IntÃ©gration** : Facilement intÃ©grable via Hugging Face Transformers

### Pourquoi un Seuil PersonnalisÃ© ?

Dans le contexte mÃ©dical, **un faux nÃ©gatif (incident non dÃ©tectÃ©) est bien plus critique qu'un faux positif**. Le seuil personnalisÃ© permet de :

1. **RÃ©duire drastiquement les faux nÃ©gatifs** : De ~124 Ã  ~1
2. **S'adapter au contexte** : Prise en compte des facteurs de risque mÃ©tier
3. **Maintenir l'accuracy globale** : Impact minimal sur la performance globale

### Trade-off Precision/Recall

Le choix mÃ©tier privilÃ©gie le **recall Ã©levÃ©** pour les incidents :
- **Seuil 0.5** : Nombreux faux nÃ©gatifs (incidents non dÃ©tectÃ©s)
- **Seuil 0.90** : Rappel beaucoup plus Ã©levÃ©, faux nÃ©gatifs rÃ©duits significativement

Cette approche garantit qu'aucun incident critique ne passe inaperÃ§u, mÃªme si cela gÃ©nÃ¨re plus d'alertes Ã  vÃ©rifier manuellement (faux positifs acceptables).

---

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Python** 3.8+
- **Transformers** (Hugging Face) : ModÃ¨les prÃ©-entraÃ®nÃ©s
- **Datasets** (Hugging Face) : Gestion des donnÃ©es
- **scikit-learn** : MÃ©triques et Ã©valuation
- **PyTorch** : Backend de calcul
- **matplotlib/seaborn** : Visualisations

---

## ğŸ“š Documentation ComplÃ¨te

Pour plus de dÃ©tails, consultez :

- **[MÃ©thodologie dÃ©taillÃ©e](docs/METHODOLOGY.md)** : Pipeline complet, prÃ©processing, entraÃ®nement
- **[Optimisation du seuil](docs/THRESHOLD_OPTIMIZATION.md)** : Algorithme, facteurs de risque, exemples
- **[RÃ©sultats](docs/RESULTS.md)** : MÃ©triques dÃ©taillÃ©es, matrices de confusion, analyses

---

## ğŸ“ CompÃ©tences DÃ©veloppÃ©es

Ce projet dÃ©montre :

- âœ… **NLP avancÃ©** : Fine-tuning de modÃ¨les transformer (CamemBERT)
- âœ… **Classification binaire** : Optimisation pour cas d'usage mÃ©tier
- âœ… **IngÃ©nierie des features** : IntÃ©gration de features mÃ©tier (contexte temporel, type de transport)
- âœ… **Optimisation mÃ©tier** : Trade-off precision/recall adaptÃ© au domaine
- âœ… **Ã‰valuation** : MÃ©triques adaptÃ©es au contexte (focus sur recall)
- âœ… **Python/ML** : Transformers, scikit-learn, PyTorch

---

## ğŸ“ Notes Importantes

- âš ï¸ **Aucune donnÃ©e confidentielle** : Les exemples prÃ©sentÃ©s sont fictifs
- âš ï¸ **Projet portfolio** : Ce dÃ©pÃ´t est une vitrine technique, non exÃ©cutable
- âš ï¸ **Source de vÃ©ritÃ©** : Les rÃ©sultats et mÃ©thodologie sont basÃ©s sur le rapport de stage (source canonique)
- âš ï¸ **DonnÃ©es confidentielles** : Aucune donnÃ©e rÃ©elle de l'entreprise n'est prÃ©sente dans ce dÃ©pÃ´t
- ğŸ“š **Documentation complÃ¨te** : Voir le dossier `docs/` pour les dÃ©tails techniques

## ğŸš€ Installation (Pour rÃ©fÃ©rence uniquement)

Ce projet est prÃ©sentÃ© Ã  des fins de dÃ©monstration. Pour reproduire l'environnement :

```bash
pip install -r requirements.txt
```

**Note** : Les notebooks nÃ©cessitent un accÃ¨s GPU (Google Colab recommandÃ©) pour l'entraÃ®nement.

---

## ğŸ‘¤ Auteur

**Mohamed Ben Amor**  
Stage AnnÃ©e 1 - Projet de Classification NLP

---

## ğŸ“„ Licence

Ce projet est prÃ©sentÃ© Ã  des fins de dÃ©monstration et de portfolio.

---

## ğŸ”— RÃ©fÃ©rences

- [CamemBERT](https://huggingface.co/camembert-base) - ModÃ¨le de langue franÃ§ais
- [Hugging Face Transformers](https://huggingface.co/docs/transformers) - BibliothÃ¨que NLP
- [scikit-learn](https://scikit-learn.org/) - Machine Learning en Python

---

## ğŸ“Œ Topics GitHub RecommandÃ©s

Pour amÃ©liorer la dÃ©couvrabilitÃ© sur GitHub, ajoutez ces topics :
- `nlp`
- `camembert`
- `transformers`
- `classification`
- `french-nlp`
- `machine-learning`
- `deep-learning`
- `huggingface`
- `portfolio`
- `medical-ai`

---

*DerniÃ¨re mise Ã  jour : Janvier 2026*
